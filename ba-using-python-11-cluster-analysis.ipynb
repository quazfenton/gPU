{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12813740,"sourceType":"datasetVersion","datasetId":8102449}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:30.380464Z","iopub.execute_input":"2025-08-20T07:21:30.380795Z","iopub.status.idle":"2025-08-20T07:21:30.395742Z","shell.execute_reply.started":"2025-08-20T07:21:30.380776Z","shell.execute_reply":"2025-08-20T07:21:30.394756Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 1: Load and explore the data**\n\nWhat are the different variables in the dataset?\nWhat do these variables tell us about the customer?\nAre these useful variables to help us understand the customer behavior?","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset\ndf = pd.read_csv(\"/kaggle/input/customer-segmentation-dataset-1/customer_dataset.csv\")\n\n# Preview the data\nprint(df.head())\nprint(df.info())\nprint(df.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:30.397405Z","iopub.execute_input":"2025-08-20T07:21:30.397766Z","iopub.status.idle":"2025-08-20T07:21:30.430087Z","shell.execute_reply.started":"2025-08-20T07:21:30.397737Z","shell.execute_reply":"2025-08-20T07:21:30.429005Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 2: Data Cleaning**\n\nCheck if there are missing values and replace missing values with median if the variable is continuous.\nCheck if there are categorical variables and replace with numerical value.","metadata":{}},{"cell_type":"code","source":"# Handle missing values in Annual Income\ndf['Annual Income'] = df['Annual Income'].fillna(df['Annual Income'].median())\n\n# Standardize column names (optional)\ndf.columns = df.columns.str.strip().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n\n# Encode categorical variables\ndf_encoded = pd.get_dummies(df, columns=['Lifestyle', 'Engagement_Level'], drop_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:30.431032Z","iopub.execute_input":"2025-08-20T07:21:30.431323Z","iopub.status.idle":"2025-08-20T07:21:30.442953Z","shell.execute_reply.started":"2025-08-20T07:21:30.431303Z","shell.execute_reply":"2025-08-20T07:21:30.441668Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 3: Feature Scaling**\n\nThe data has to be normalized to ensure fair clustering, especially for distance based clustering algorithms like k-means. Else, the clustering can get biased by variables such as Income which have high values.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Select features for clustering\nfeatures = ['Age', 'Annual_Income', 'Spending_Score', 'Loyalty_Tier', \n            'Time_Spent_mins/week'] + [col for col in df_encoded.columns if 'Lifestyle_' in col or 'Engagement_Level_' in col]\n\n# Scale features\nscaler = StandardScaler()\nscaled_data = scaler.fit_transform(df_encoded[features])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:30.445045Z","iopub.execute_input":"2025-08-20T07:21:30.445346Z","iopub.status.idle":"2025-08-20T07:21:30.467825Z","shell.execute_reply.started":"2025-08-20T07:21:30.445317Z","shell.execute_reply":"2025-08-20T07:21:30.466762Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 4: Determine optimal number of clusters (Elbow Method)**\n\nInertia is the sum of squared distances between each data point and the centroid of its assigned cluster.\n- Lower inertia means tighter clusters.\n- But too many clusters will always reduce inertia—so we need a balance.\n\nThe Elbow method plots the inertia of the different cluster sizes. The point at which the inertia plateaus is the correct number of clusters to extract.","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\n\ninertia = []\nfor k in range(1, 11):\n    kmeans = KMeans(n_clusters=k, random_state=42)\n    kmeans.fit(scaled_data)\n    inertia.append(kmeans.inertia_)\n\nplt.plot(range(1, 11), inertia, marker='o')\nplt.title('Elbow Method')\nplt.xlabel('Number of Clusters')\nplt.ylabel('Inertia')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:30.468869Z","iopub.execute_input":"2025-08-20T07:21:30.469206Z","iopub.status.idle":"2025-08-20T07:21:30.830283Z","shell.execute_reply.started":"2025-08-20T07:21:30.469176Z","shell.execute_reply":"2025-08-20T07:21:30.829366Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 5 - Evaluate Cluster Quality (Silhouette Score)**\n\nAssesses how well-separated clusters are, and ranges from -1 to 1.","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import StandardScaler\n\n# Step 1: Preprocess your data (optional but recommended)\nfeatures = df.drop('Cluster', axis=1, errors='ignore')  # Drop existing labels if present\nfeatures_scaled = StandardScaler().fit_transform(features.select_dtypes(include='number'))\n\n# Step 2: Try different values of k and compute silhouette scores\nsilhouette_scores = []\nk_values = range(2, 10)  # You can adjust this range\n\nfor k in k_values:\n    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n    labels = kmeans.fit_predict(features_scaled)\n    score = silhouette_score(features_scaled, labels)\n    silhouette_scores.append(score)\n    print(f\"k = {k}, Silhouette Score = {score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:30.831305Z","iopub.execute_input":"2025-08-20T07:21:30.831648Z","iopub.status.idle":"2025-08-20T07:21:31.013424Z","shell.execute_reply.started":"2025-08-20T07:21:30.831611Z","shell.execute_reply":"2025-08-20T07:21:31.012375Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.plot(k_values, silhouette_scores, marker='o')\nplt.title(\"Silhouette Score vs Number of Clusters\")\nplt.xlabel(\"Number of Clusters (k)\")\nplt.ylabel(\"Silhouette Score\")\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:31.014379Z","iopub.execute_input":"2025-08-20T07:21:31.014741Z","iopub.status.idle":"2025-08-20T07:21:31.219584Z","shell.execute_reply.started":"2025-08-20T07:21:31.014719Z","shell.execute_reply":"2025-08-20T07:21:31.218685Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 6 : Apply Clustering Algorithm**\n\nThe first step is to decide the clustering algorithm. \n- Common choices:\n    - K-Means (centroid-based, efficient)\n    - Hierarchical (dendrogram-based, interpretable)\n    - DBSCAN (density-based, handles noise)\n- The decision depends on data shape, noise, and desired interpretability.\n\nThe next step is to decide the number of clusters to form. \nThe output is to assign each customer to a cluster.","metadata":{}},{"cell_type":"code","source":"# Choose optimal k (e.g., 4)\nkmeans = KMeans(n_clusters=4, random_state=42)\ndf['Cluster'] = kmeans.fit_predict(scaled_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:31.220503Z","iopub.execute_input":"2025-08-20T07:21:31.22074Z","iopub.status.idle":"2025-08-20T07:21:31.245162Z","shell.execute_reply.started":"2025-08-20T07:21:31.220722Z","shell.execute_reply":"2025-08-20T07:21:31.243159Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 7: Visualize Clusters**\n\nInterpret clusters visually and discuss business implications.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n\n# Loyalty tier vs. Spending Score colored by cluster\nsns.scatterplot(data=df, x='Loyalty_Tier', y='Spending_Score', hue='Cluster', palette='Set2')\nplt.title('Customer Segments by Loyalty Tier and Spending Score')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:31.247124Z","iopub.execute_input":"2025-08-20T07:21:31.247456Z","iopub.status.idle":"2025-08-20T07:21:31.547309Z","shell.execute_reply.started":"2025-08-20T07:21:31.247428Z","shell.execute_reply":"2025-08-20T07:21:31.546438Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Spending score vs. Annual Income colored by cluster\nsns.scatterplot(data=df, x='Annual_Income', y='Spending_Score', hue='Cluster', palette='Set2')\nplt.title('Customer Segments by Annual Income and Spending Score')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:31.548725Z","iopub.execute_input":"2025-08-20T07:21:31.549083Z","iopub.status.idle":"2025-08-20T07:21:31.828651Z","shell.execute_reply.started":"2025-08-20T07:21:31.549056Z","shell.execute_reply":"2025-08-20T07:21:31.827688Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Age vs. Spending Score colored by cluster\nsns.scatterplot(data=df, x='Age', y='Spending_Score', hue='Cluster', palette='Set2')\nplt.title('Customer Segments by Age and Spending Score')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:31.829644Z","iopub.execute_input":"2025-08-20T07:21:31.82997Z","iopub.status.idle":"2025-08-20T07:21:32.128951Z","shell.execute_reply.started":"2025-08-20T07:21:31.829945Z","shell.execute_reply":"2025-08-20T07:21:32.127666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Lifestyle vs. Income colored by cluster\nsns.scatterplot(data=df, x='Lifestyle', y='Annual_Income', hue='Cluster', palette='Set2')\nplt.title('Customer Segments by Lifestyle and Income')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:32.130147Z","iopub.execute_input":"2025-08-20T07:21:32.131087Z","iopub.status.idle":"2025-08-20T07:21:32.408958Z","shell.execute_reply.started":"2025-08-20T07:21:32.13106Z","shell.execute_reply":"2025-08-20T07:21:32.407919Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\n\n# Choose any three numeric variables for the axes\nx_var = 'Age'\ny_var = 'Annual_Income'\nz_var = 'Spending_Score'\n\n# Drop rows with missing values in selected columns\nplot_df = df[[x_var, y_var, z_var, 'Cluster']].dropna()\n\n# Create the 3D scatter plot\nfig = plt.figure(figsize=(10, 8))\nax = fig.add_subplot(111, projection='3d')\n\nscatter = ax.scatter(\n    plot_df[x_var],\n    plot_df[y_var],\n    plot_df[z_var],\n    c=plot_df['Cluster'],\n    cmap='viridis',\n    s=50,\n    alpha=0.8\n)\n\n# Label the axes\nax.set_xlabel(x_var)\nax.set_ylabel(y_var)\nax.set_zlabel(z_var)\nax.set_title(\"3D Cluster Plot\")\n\n# Add color legend\nplt.colorbar(scatter, label='Cluster')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:32.410165Z","iopub.execute_input":"2025-08-20T07:21:32.410438Z","iopub.status.idle":"2025-08-20T07:21:32.687283Z","shell.execute_reply.started":"2025-08-20T07:21:32.410417Z","shell.execute_reply":"2025-08-20T07:21:32.686305Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Step 8: Cluster Profiling**\n\nSummarizes each cluster’s average characteristics.","metadata":{}},{"cell_type":"code","source":"# Group by cluster to understand characteristics\nnumeric_cols = df.select_dtypes(include='number').columns\ncluster_profile = df.groupby('Cluster')[numeric_cols].mean()\nprint(cluster_profile)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-20T07:21:32.68828Z","iopub.execute_input":"2025-08-20T07:21:32.688573Z","iopub.status.idle":"2025-08-20T07:21:32.701526Z","shell.execute_reply.started":"2025-08-20T07:21:32.688542Z","shell.execute_reply":"2025-08-20T07:21:32.700576Z"}},"outputs":[],"execution_count":null}]}